\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage[document]{ragged2e}
\setlength{\parskip}{1em}

\usepackage[T1]{fontenc}
\usepackage{libertine}

\title{Statement of Purpose}
\author{Junyong Zhao}
\date{October 16, 2023}

\begin{document}
\maketitle

\section{Research Projects}
I am currently working on a research project that focuses on workload balancing
for storage disaggregated cloud database. This project aims to mitigate workload
imbalance due to skewed scan requests and reduce the tail latency due to
workload imbalance. This project is currently in the experiment and evaluation
phase and we are planning to make a submission during this semester.

\section{Driving Forces}
I am the main driving force behind this project. The problem we are trying to
solve is derived from the straggler problem in distributed systems. Advised by
Dr. Lei Cao, we settled a general direction of using replications to achieve
lower latency based on existing consistent hashing architecture. I did a
comprehensive literature review to identify related works in other domains such
as MapReduce systems and Memcached. I proposed an initial solution that actively
copy hot data and developed a primitive simulation framework with Ryan Murphy, a
former master student in the department. Due to the complexity and existence of
related work, I proposed a second solution that improves consistent hashing with
trackable random jumps. I have further improved the existing simulation
framework to support the newer version of the solution and I am currently
working on implementing evaluation baselines.

\section{Contributions to the Field}
For storage disaggregated database, latency is an important performance metric.
Balancing the workload for each node will help reduce the probability of
stragglers and therefore, reduce tail latency. It should also be noticed that
unlike other local database, storage disaggregated database in the cloud has an
extra cost in reading from the remote storage layer, and reuse cache on each
node is also an important aspect in reducing latency. To address these
requirements, consistent hashing has served as a primary scheduling mechanism
with two main advantages: 1) it preserves cache locality by scheduling similar
tasks together, and 2) it doesn't require rehash when nodes fail or join the
system. However, the consistent hashing will not balance skewed workload if a
lot of scan requests favor some hot data. Our project contribute to solve this
problem by reassign requests to other non-overloaded nodes. During this process,
we also use trackable random jump to preserve cache locality so that the
reassigned requests will reuse cached data on computing nodes as much as
possible in order to avoid extra cost of reading remote storage.

\end{document}
